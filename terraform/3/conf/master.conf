#cloud-config
coreos:
  etcd2:
    discovery: ${etcd_discovery_url}
    advertise-client-urls: https://$private_ipv4:2379
    initial-advertise-peer-urls: https://$private_ipv4:2380
    listen-client-urls: https://0.0.0.0:2379
    listen-peer-urls: https://$private_ipv4:2380
    cert-file: /etc/ssl/etcd/server.pem
    key-file: /etc/ssl/etcd/server-key.pem
    client-cert-auth: true
    trusted-ca-file: /etc/ssl/etcd/ca.pem
    peer-cert-file: /etc/ssl/etcd/server.pem
    peer-key-file: /etc/ssl/etcd/server-key.pem
    peer-client-cert-auth: true
    peer-trusted-ca-file: /etc/ssl/etcd/ca.pem
  flannel:
    etcd_endpoints: https://$private_ipv4:2379
    etcd_cafile: /etc/ssl/etcd/ca.pem
    etcd_certfile: /etc/ssl/etcd/server.pem
    etcd_keyfile: /etc/ssl/etcd/server-key.pem
  locksmith:
    endpoint: https://$private_ipv4:2379
    etcd_cafile: /etc/ssl/etcd/ca.pem
    etcd_certfile: /etc/ssl/etcd/server.pem
    etcd_keyfile: /etc/ssl/etcd/server-key.pem
  update:
    reboot-strategy: "etcd-lock"
  units:
    - name: "etcd2.service"
      command: "start"
      drop-ins:
        - name: 40-AfterBootstrap.conf
          content: |
            [Unit]
            Requires=bootstrap-master-certs.service
            After=bootstrap-master-certs.service
    - name: "bootstrap-master-certs.service"
      command: start
      content: |
        [Unit]
        Before=etcd2.service
        Before=flanneld.service
        [Service]
        Type=oneshot
        ExecStart=/root/bootstrap/bootstrap-master-certs.sh
        Restart=no
    - name: "flanneld.service"
      command: "start"
      drop-ins:
        - name: 40-AfterEtcd.conf
          content: |
            [Unit]
            Requires=etcd2.service
            After=etcd2.service
        - name: 50-ExecStartPre-networkconfig.conf
          content: |
            [Service]
            ExecStartPre=sleep 10
            ExecStartPre=/usr/bin/etcdctl --endpoints https://$private_ipv4:2379 \
                 --ca-file /etc/ssl/etcd/ca.pem --cert-file /etc/ssl/etcd/server.pem --key-file /etc/ssl/etcd/server-key.pem \
                 set /coreos.com/network/config '{"Network":"${pod_network}","Backend":{"Type":"vxlan"}}'
    - name: "docker.service"
      command: start
      drop-ins:
        - name: 40-Flannel.conf
          content: |
            [Unit]
            Requires=flanneld.service
            After=flanneld.service
    - name: "kubelet.service"
      command: start
      content: |
        [Unit]
        Requires=docker.service
        After=docker.service

        [Service]
        ExecStartPre=/usr/bin/mkdir -p /etc/kubernetes/manifests
        ExecStartPre=/usr/bin/mkdir -p /var/log/containers

        Environment=KUBELET_VERSION=${kubernetes_version}
        Environment="RKT_OPTS=--volume var-log,kind=host,source=/var/log \
          --mount volume=var-log,target=/var/log \
          --volume dns,kind=host,source=/etc/resolv.conf \
          --mount volume=dns,target=/etc/resolv.conf \
          --volume ssl-kubernetes,kind=host,source=/etc/ssl/kubernetes,readOnly=true \
          --mount volume=ssl-kubernetes,target=/etc/ssl/kubernetes"

        ExecStart=/usr/lib/coreos/kubelet-wrapper \
          --api-servers=http://127.0.0.1:8080 \
          --network-plugin= \
          --register-schedulable=false \
          --allow-privileged=true \
          --config=/etc/kubernetes/manifests \
          --hostname-override=$private_ipv4 \
          --cluster-dns=${dns_service_ip} \
          --cluster-domain=cluster.local
        Restart=always
        RestartSec=10

        [Install]
        WantedBy=multi-user.target
    - name: "bootstrap-master-kubernetes.service"
      command: start
      content: |
        [Unit]
        Requires=kubelet.service
        After=kubelet.service
        [Service]
        Type=oneshot
        ExecStart=/root/bootstrap/bootstrap-master-kubernetes.sh
        Restart=no
write_files:
  - path: "/root/bootstrap/api-openssl.cnf"
    permissions: "0644"
    owner: "root"
    content: |
      [req]
      req_extensions = v3_req
      distinguished_name = req_distinguished_name
      [req_distinguished_name]
      [ v3_req ]
      basicConstraints = CA:FALSE
      keyUsage = nonRepudiation, digitalSignature, keyEncipherment
      subjectAltName = @alt_names
      [alt_names]
      DNS.1 = kubernetes
      DNS.2 = kubernetes.default
      DNS.3 = kubernetes.default.svc
      DNS.4 = kubernetes.default.svc.cluster.local
      DNS.5 = $private_ipv4
      IP.1 = ${kubernetes_service_ip}
      IP.2 = $private_ipv4
  - path: "/root/bootstrap/worker-openssl.cnf"
    permissions: "0644"
    owner: "root"
    content: |
      [req]
      req_extensions = v3_req
      distinguished_name = req_distinguished_name
      [req_distinguished_name]
      [ v3_req ]
      basicConstraints = CA:FALSE
      keyUsage = nonRepudiation, digitalSignature, keyEncipherment
      subjectAltName = @alt_names
      [alt_names]
      DNS.1 = $ENV::WORKER_IP
      IP.1 = $ENV::WORKER_IP
  - path: "/root/bootstrap/bootstrap-master-certs.sh"
    permissions: "0755"
    owner: "root"
    content: |
      #!/usr/bin/env bash
      set -e
      set -u

      if [ -f /root/bootstrap/.done ]; then
        echo "Already done, exiting..."
        exit 0
      fi

      echo "Creating keys"

      cd /root/bootstrap

      # generate CA
      openssl genrsa -out ca-key.pem 2048
      openssl req -x509 -new -nodes -key ca-key.pem -days 10000 -out ca.pem -subj "/CN=ca"

      # generate certs for the API server
      openssl genrsa -out server-key.pem 2048
      openssl req -new -key server-key.pem -out server.csr -subj "/CN=server" -config api-openssl.cnf
      openssl x509 -req -in server.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out server.pem -days 365 -extensions v3_req -extfile api-openssl.cnf

      # change permissions
      chmod 700 .
      chmod 600 *.pem *.csr

      # copy them to the appropriate location
      mkdir -p /etc/ssl/kubernetes
      cp ca.pem /etc/ssl/kubernetes/ca.pem
      cp server.pem /etc/ssl/kubernetes/server.pem
      cp server-key.pem /etc/ssl/kubernetes/server-key.pem

      mkdir -p /etc/ssl/etcd
      cp ca.pem /etc/ssl/etcd/ca.pem
      cp server.pem /etc/ssl/etcd/server.pem
      cp server-key.pem /etc/ssl/etcd/server-key.pem
      chown -R etcd:etcd /etc/ssl/etcd

      touch /root/bootstrap/.done

  - path: "/root/bootstrap/bootstrap-master-kubernetes.sh"
    permissions: "0755"
    owner: "root"
    content: |
      #!/usr/bin/env bash
      set -e
      set -u

      until curl --silent http://127.0.0.1:8080/version 2>/dev/null | grep gitVersion > /dev/null; do
        echo "Waiting for kube server to start up..."
        sleep 10
      done

      echo "Installing and setting up kubectl"

      if ! [ -f /opt/bin/kubectl ]; then
        mkdir -p /opt/bin
        curl -o /opt/bin/kubectl https://storage.googleapis.com/kubernetes-release/release/v1.4.3/bin/linux/amd64/kubectl
        chmod 700 /opt/bin/kubectl
        /opt/bin/kubectl config set-cluster default-cluster --server=https://$private_ipv4 --certificate-authority=/etc/ssl/kubernetes/ca.pem
        /opt/bin/kubectl config set-credentials default-admin --certificate-authority=/etc/ssl/kubernetes/ca.pem --client-key=/etc/ssl/kubernetes/server-key.pem --client-certificate=/etc/ssl/kubernetes/server.pem
        /opt/bin/kubectl config set-context default-system --cluster=default-cluster --user=default-admin
        /opt/bin/kubectl config use-context default-system
        /opt/bin/kubectl create -f /root/bootstrap/kubernetes-addons.yaml
      fi
  - path: "/root/bootstrap/kubernetes-addons.yaml"
    permission: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Service
      metadata:
        name: kube-dns
        namespace: kube-system
        labels:
          k8s-app: kube-dns
          kubernetes.io/cluster-service: "true"
          kubernetes.io/name: "KubeDNS"
      spec:
        selector:
          k8s-app: kube-dns
        clusterIP: ${dns_service_ip}
        ports:
        - name: dns
          port: 53
          protocol: UDP
        - name: dns-tcp
          port: 53
          protocol: TCP


      ---


      apiVersion: v1
      kind: ReplicationController
      metadata:
        name: kube-dns-v20
        namespace: kube-system
        labels:
          k8s-app: kube-dns
          version: v20
          kubernetes.io/cluster-service: "true"
      spec:
        replicas: 1
        selector:
          k8s-app: kube-dns
          version: v20
        template:
          metadata:
            labels:
              k8s-app: kube-dns
              version: v20
            annotations:
              scheduler.alpha.kubernetes.io/critical-pod: ''
              scheduler.alpha.kubernetes.io/tolerations: '[{"key":"CriticalAddonsOnly", "operator":"Exists"}]'
          spec:
            containers:
            - name: kubedns
              image: gcr.io/google_containers/kubedns-amd64:1.8
              resources:
                limits:
                  memory: 170Mi
                requests:
                  cpu: 100m
                  memory: 70Mi
              livenessProbe:
                httpGet:
                  path: /healthz-kubedns
                  port: 8080
                  scheme: HTTP
                initialDelaySeconds: 60
                timeoutSeconds: 5
                successThreshold: 1
                failureThreshold: 5
              readinessProbe:
                httpGet:
                  path: /readiness
                  port: 8081
                  scheme: HTTP
                initialDelaySeconds: 3
                timeoutSeconds: 5
              args:
              - --domain=cluster.local.
              - --dns-port=10053
              ports:
              - containerPort: 10053
                name: dns-local
                protocol: UDP
              - containerPort: 10053
                name: dns-tcp-local
                protocol: TCP
            - name: dnsmasq
              image: gcr.io/google_containers/kube-dnsmasq-amd64:1.4
              livenessProbe:
                httpGet:
                  path: /healthz-dnsmasq
                  port: 8080
                  scheme: HTTP
                initialDelaySeconds: 60
                timeoutSeconds: 5
                successThreshold: 1
                failureThreshold: 5
              args:
              - --cache-size=1000
              - --no-resolv
              - --server=127.0.0.1#10053
              - --log-facility=-
              ports:
              - containerPort: 53
                name: dns
                protocol: UDP
              - containerPort: 53
                name: dns-tcp
                protocol: TCP
            - name: healthz
              image: gcr.io/google_containers/exechealthz-amd64:1.2
              resources:
                limits:
                  memory: 50Mi
                requests:
                  cpu: 10m
                  memory: 50Mi
              args:
              - --cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1 >/dev/null
              - --url=/healthz-dnsmasq
              - --cmd=nslookup kubernetes.default.svc.cluster.local 127.0.0.1:10053 >/dev/null
              - --url=/healthz-kubedns
              - --port=8080
              - --quiet
              ports:
              - containerPort: 8080
                protocol: TCP
            dnsPolicy: Default

      ---

      apiVersion: v1
      kind: ReplicationController
      metadata:
        name: kubernetes-dashboard-v1.4.1
        namespace: kube-system
        labels:
          k8s-app: kubernetes-dashboard
          version: v1.4.1
          kubernetes.io/cluster-service: "true"
      spec:
        replicas: 1
        selector:
          k8s-app: kubernetes-dashboard
        template:
          metadata:
            labels:
              k8s-app: kubernetes-dashboard
              version: v1.4.1
              kubernetes.io/cluster-service: "true"
            annotations:
              scheduler.alpha.kubernetes.io/critical-pod: ''
              scheduler.alpha.kubernetes.io/tolerations: '[{"key":"CriticalAddonsOnly", "operator":"Exists"}]'
          spec:
            containers:
            - name: kubernetes-dashboard
              image: gcr.io/google_containers/kubernetes-dashboard-amd64:v1.4.1
              resources:
                limits:
                  cpu: 100m
                  memory: 50Mi
                requests:
                  cpu: 100m
                  memory: 50Mi
              ports:
              - containerPort: 9090
              livenessProbe:
                httpGet:
                  path: /
                  port: 9090
                initialDelaySeconds: 30
                timeoutSeconds: 30

      ---

      apiVersion: v1
      kind: Service
      metadata:
        name: kubernetes-dashboard
        namespace: kube-system
        labels:
          k8s-app: kubernetes-dashboard
          kubernetes.io/cluster-service: "true"
      spec:
        selector:
          k8s-app: kubernetes-dashboard
        ports:
        - port: 80
          targetPort: 9090

  - path: "/root/bootstrap/generate-worker-cert.sh"
    permissions: "0755"
    owner: "root"
    content: |
      #!/usr/bin/env bash
      set -e
      set -u

      until [ -f /root/bootstrap/.done ]; do
        echo "Waiting for CA bootstrap to finish"
        sleep 5
      done

      cd /root/bootstrap

      WORKER_FQDN=$1
      WORKER_IP=$2

      openssl genrsa -out $WORKER_FQDN-worker-key.pem 2048
      WORKER_IP=$WORKER_IP openssl req -new -key $WORKER_FQDN-worker-key.pem -out $WORKER_FQDN-worker.csr -subj "/CN=$WORKER_FQDN" -config worker-openssl.cnf
      WORKER_IP=$WORKER_IP openssl x509 -req -in $WORKER_FQDN-worker.csr -CA ca.pem -CAkey ca-key.pem -CAcreateserial -out $WORKER_FQDN-worker.pem -days 365 -extensions v3_req -extfile worker-openssl.cnf

      chown core:core $WORKER_FQDN-worker-key.pem
      chown core:core $WORKER_FQDN-worker.pem

      mv $WORKER_FQDN-worker-key.pem /home/core
      mv $WORKER_FQDN-worker.pem /home/core

      cp ca.pem /home/core/$WORKER_FQDN-ca.pem
      chown core:core /home/core/$WORKER_FQDN-ca.pem
      chmod 755 /home/core/$WORKER_FQDN-ca.pem

  - path: "/etc/kubernetes/manifests/kube-apiserver.yaml"
    permissions: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-apiserver
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-apiserver
          image: quay.io/coreos/hyperkube:${kubernetes_version}
          command:
          - /hyperkube
          - apiserver
          - --bind-address=0.0.0.0
          - --etcd-servers=https://$private_ipv4:2379
          - --etcd-cafile=/etc/ssl/kubernetes/ca.pem
          - --etcd-certfile=/etc/ssl/kubernetes/server.pem
          - --etcd-keyfile=/etc/ssl/kubernetes/server-key.pem
          - --allow-privileged=true
          - --service-cluster-ip-range=${service_ip_range}
          - --secure-port=443
          - --advertise-address=$private_ipv4
          - --admission-control=NamespaceLifecycle,LimitRanger,ServiceAccount,DefaultStorageClass,ResourceQuota
          - --tls-cert-file=/etc/ssl/kubernetes/server.pem
          - --tls-private-key-file=/etc/ssl/kubernetes/server-key.pem
          - --client-ca-file=/etc/ssl/kubernetes/ca.pem
          - --service-account-key-file=/etc/ssl/kubernetes/server-key.pem
          - --runtime-config=extensions/v1beta1=true,extensions/v1beta1/networkpolicies=true
          ports:
          - containerPort: 443
            hostPort: 443
            name: https
          - containerPort: 8080
            hostPort: 8080
            name: local
          volumeMounts:
          - mountPath: /etc/ssl/kubernetes
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/ssl/kubernetes
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host
  - path: "/etc/kubernetes/manifests/kube-proxy.yaml"
    permissions: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-proxy
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-proxy
          image: quay.io/coreos/hyperkube:${kubernetes_version}
          command:
          - /hyperkube
          - proxy
          - --master=http://127.0.0.1:8080
          - --proxy-mode=iptables
          securityContext:
            privileged: true
          volumeMounts:
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host
  - path: "/etc/kubernetes/manifests/kube-controller-manager.yaml"
    permissions: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-controller-manager
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-controller-manager
          image: quay.io/coreos/hyperkube:${kubernetes_version}
          command:
          - /hyperkube
          - controller-manager
          - --master=http://127.0.0.1:8080
          - --leader-elect=true
          - --service-account-private-key-file=/etc/ssl/kubernetes/server-key.pem
          - --root-ca-file=/etc/ssl/kubernetes/ca.pem
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10252
            initialDelaySeconds: 15
            timeoutSeconds: 1
          volumeMounts:
          - mountPath: /etc/ssl/kubernetes
            name: ssl-certs-kubernetes
            readOnly: true
          - mountPath: /etc/ssl/certs
            name: ssl-certs-host
            readOnly: true
        volumes:
        - hostPath:
            path: /etc/ssl/kubernetes
          name: ssl-certs-kubernetes
        - hostPath:
            path: /usr/share/ca-certificates
          name: ssl-certs-host
  - path: "/etc/kubernetes/manifests/kube-scheduler.yaml"
    permissions: "0644"
    owner: "root"
    content: |
      apiVersion: v1
      kind: Pod
      metadata:
        name: kube-scheduler
        namespace: kube-system
      spec:
        hostNetwork: true
        containers:
        - name: kube-scheduler
          image: quay.io/coreos/hyperkube:${kubernetes_version}
          command:
          - /hyperkube
          - scheduler
          - --master=http://127.0.0.1:8080
          - --leader-elect=true
          livenessProbe:
            httpGet:
              host: 127.0.0.1
              path: /healthz
              port: 10251
            initialDelaySeconds: 15
            timeoutSeconds: 1
